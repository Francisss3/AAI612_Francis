{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francisss3/AAI612_Francis/blob/main/Notebook3_2_2_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNwSy7KYNvhi"
      },
      "source": [
        "\n",
        "\n",
        "# AAI612: Deep Learning & its Applications\n",
        "\n",
        "\n",
        "*Notebook 3.2: Practice with Images*\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/harmanani/AAI612/blob/main/Week3/Notebook3.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvhDmx0pNvhm"
      },
      "source": [
        "# Image Classification with the MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OvGmZovNvhm"
      },
      "source": [
        "Historically, the expert systems that were built to do classification similar this lab were extremely complicated, and people spent their careers building them (check out the references on the [official MNIST page](http://yann.lecun.com/exdb/mnist/) and the years milestones were reached)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skn_gqnYNvhm"
      },
      "source": [
        "## The Problem: Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRs1_6RuNvhn"
      },
      "source": [
        "In traditional programming, the programmer is able to articulate rules and conditions in their code that their program can then use to act in the correct way. This approach continues to work exceptionally well for a huge variety of problems.\n",
        "\n",
        "Image classification, which asks a program to correctly classify an image it has never seen before into its correct class, is near impossible to solve with traditional programming techniques. How could a programmer possibly define the rules and conditions to correctly classify a huge variety of images, especially taking into account images that they have never seen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXS49LXyNvhn"
      },
      "source": [
        "## The Solution: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfecX4ouNvhn"
      },
      "source": [
        "Deep learning excels at pattern recognition by trial and error. By training a deep neural network with sufficient data, and providing the network with feedback on its performance via training, the network can identify, though a huge amount of iteration, its own set of conditions by which it can act in the correct way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufs5hXr5Nvho"
      },
      "source": [
        "## The MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjeOZQbXNvho"
      },
      "source": [
        "In the history of deep learning, the accurate image classification of the [MNSIT dataset](http://yann.lecun.com/exdb/mnist/), a collection of 70,000 grayscale images of handwritten digits from 0 to 9, was a major development. While today the problem is considered trivial, doing image classification with MNIST has become a kind of \"Hello World\" for deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT6G0TmRNvho"
      },
      "source": [
        "Here are 40 of the images included in the MNIST dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Fkn-KMNvho"
      },
      "source": [
        "<img src=\"./images/mnist.jpg\" style=\"width: 600px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfk6ONOfNvhp"
      },
      "source": [
        "## Training and Validation Data and Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTbtMXkJNvhp"
      },
      "source": [
        "When working with images for deep learning, we need both the images themselves, usually denoted as `X`, and also, correct [labels](https://developers.google.com/machine-learning/glossary#label) for these images, usually denoted as `Y`. Furthermore, we need `X` and `Y` values both for *training* the model, and then, a separate set of `X` and `Y` values for *validating* the performance of the model after it has been trained. Therefore, we need 4 segments of data for the MNIST dataset:\n",
        "\n",
        "1. `x_train`: Images used for training the neural network\n",
        "2. `y_train`: Correct labels for the `x_train` images, used to evaluate the model's predictions during training\n",
        "3. `x_valid`: Images set aside for validating the performance of the model after it has been trained\n",
        "4. `y_valid`: Correct labels for the `x_valid` images, used to evaluate the model's predictions after it has been trained\n",
        "\n",
        "The process of preparing data for analysis is called [Data Engineering](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). To learn more about the differences between training data and validation data (as well as test data), check out [this article](https://machinelearningmastery.com/difference-test-validation-datasets/) by Jason Brownlee."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq21M-HQNvhp"
      },
      "source": [
        "## Loading the Data Into Memory (with Keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB_718HvNvhq"
      },
      "source": [
        "There are many [deep learning frameworks](https://developer.nvidia.com/deep-learning-frameworks), each with their own merits. In this workshop we will be working with [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner), and specifically with the [Keras API](https://keras.io/). Keras has many useful built in functions designed for the computer vision tasks. It is also a legitimate choice for deep learning in a professional setting due to its [readability](https://blog.pragmaticengineer.com/readable-code/) and efficiency, though it is not alone in this regard, and it is worth investigating a variety of frameworks when beginning a deep learning project.\n",
        "\n",
        "One of the many helpful features that Keras provides are modules containing many helper methods for [many common datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets), including MNIST.\n",
        "\n",
        "We will begin by loading the Keras dataset module for MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K8YM0timNvhq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udZaPkuDNvhs"
      },
      "source": [
        "With the `mnist` module, we can easily load the MNIST data, already partitioned into images and labels for both training and validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZP2rc-sNvhs",
        "outputId": "fc73d513-fa59-4c16-8984-7e9dec55b8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# the data, split between train and validation sets\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yOVu6o4Nvhs"
      },
      "source": [
        "## Exploring the MNIST Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWP7L0wpNvht"
      },
      "source": [
        "We stated above that the MNIST dataset contained 70,000 grayscale images of handwritten digits. By executing the following cells, we can see that Keras has partitioned 60,000 of these images for training, and 10,000 for validation (after training), and also, that each image itself is a 2D array with the dimensions 28x28:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "010p3qdBNvht",
        "outputId": "07c0483b-db5d-4d12-c1e0-0c166c2d1dea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69u6Biq9Nvht",
        "outputId": "2dceaaaa-0ea0-4071-a7c7-8fe535a90a8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x_valid.shape\n",
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--AtypIzNvhu"
      },
      "source": [
        "Furthermore, we can see that these 28x28 images are represented as a collection of unsigned 8-bit integer values between 0 and 255, the values corresponding with a pixel's grayscale value where `0` is black, `255` is white, and all other values are in between:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6SgKiMqNvhu",
        "outputId": "88b1f11f-13f8-405c-be9f-b9f70930c002"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-JIwcX7Nvhu",
        "outputId": "d1ee0346-be67-40ad-ba78-8f0eb23e3276"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd1DB-Z1Nvhu",
        "outputId": "df2d6dd7-3465-408f-fb6d-46b1961d6b7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "GKwhz8aWNvhv",
        "outputId": "ac30ec0e-987d-41b1-d2eb-e3c828b96ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-f3a80528-23ea-454e-92f3-4f895a24c2c1\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-f3a80528-23ea-454e-92f3-4f895a24c2c1 button').onclick = (e) => {\n",
              "        document.querySelector('#id-f3a80528-23ea-454e-92f3-4f895a24c2c1').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-f3a80528-23ea-454e-92f3-4f895a24c2c1 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeT34FPaNvhv"
      },
      "source": [
        "Using [Matplotlib](https://matplotlib.org/), we can render one of these grayscale images in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "PK4F6znMNvhv",
        "outputId": "7c522959-f9ac-4cd3-9dbb-e687f40ca8f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdbc274d150>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = x_train[0]\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CltWLgGpNvhv"
      },
      "source": [
        "In this way we can now see that this is a 28x28 pixel image of a 5. Or is it a 3? The answer is in the `y_train` data, which contains correct labels for the data. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dlvCchaNvhw",
        "outputId": "ec597c73-8f44-4c7c-b71b-f3bfc1e6fac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLv-WvuaNvhw"
      },
      "source": [
        "## Preparing the Data for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ozXuPsrNvhx"
      },
      "source": [
        "In deep learning, it is common that data needs to be transformed to be in the ideal state for training. For this particular image classification problem, there are 3 tasks we should perform with the data in preparation for training:\n",
        "1. Flatten the image data, to simplify the image input into the model\n",
        "2. Normalize the image data, to make the image input values easier to work with for the model\n",
        "3. Categorize the labels, to make the label values easier to work with for the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYE4FIlnNvhx"
      },
      "source": [
        "### Flattening the Image Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd_MQ7thNvhy"
      },
      "source": [
        "Though it's possible for a deep learning model to accept a 2-dimensional image (in our case 28x28 pixels), we're going to simplify things to start and [reshape](https://www.tensorflow.org/api_docs/python/tf/reshape) each image into a single array of 784 continuous pixels (note: 28x28 = 784). This is also called flattening the image.\n",
        "\n",
        "Here we accomplish this using the helper method `reshape`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ubNP1HwQNvhy"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_valid = x_valid.reshape(10000, 784)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJPL2taNNvhz"
      },
      "source": [
        "We can confirm that the image data has been reshaped and is now a collection of 1D arrays containing 784 pixel values each:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtUq_wTeNvhz",
        "outputId": "7c57537d-61c7-42e1-cf60-020e7f61da06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAJdXt77Nvh0",
        "outputId": "0e980337-76ff-4377-9488-abfc75cbed3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJkmPADFNvh0"
      },
      "source": [
        "### Normalizing the Image Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3G9pKTeNvh1"
      },
      "source": [
        "Deep learning models are better at dealing with floating point numbers between 0 and 1 (more on this topic later). Converting integer values to floating point values between 0 and 1 is called [normalization](https://developers.google.com/machine-learning/glossary#normalization), and a simple approach we will take here to normalize the data will be to divide all the pixel values (which if you recall are between 0 and 255) by 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2OR4Nq2wNvh1"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v-qrn-INvh2"
      },
      "source": [
        "We can now see that the values are all floating point values between `0.0` and `1.0`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPgYM-_sNvh2",
        "outputId": "9430e64d-ef13-4813-ffee-9bc158aa9152"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EbH3Ex7Nvh2",
        "outputId": "01747f32-733e-4c7f-c80e-4ebf6b0528a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4DFPqhkNvh2",
        "outputId": "0c2fd4ce-daf0-4d3a-a6fa-b8b21b675b92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3cK4ohMNvh3"
      },
      "source": [
        "### Categorical Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfj4qJoVNvh3"
      },
      "source": [
        "Consider for a moment, if we were to ask, what is 7 - 2? Stating that the answer was 4 is closer than stating that the answer was 9. However, for this image classification problem, we don't want the neural network to learn this kind of reasoning: we just want it to select the correct category, and understand that if we have an image of the number 5, that guessing 4 is just as bad as guessing 9.\n",
        "\n",
        "As it stands, the labels for the images are integers between 0 and 9. Because these values represent a numerical range, the model might try to draw some conclusions about its performance based on how close to the correct numerical category it guesses.\n",
        "\n",
        "Therefore, we will do something to our data called categorical encoding. This kind of transformation modifies the data so that each value is a collection of all possible categories, with the actual category that this particular value is set as true.\n",
        "\n",
        "As a simple example, consider if we had 3 categories: red, blue, and green. For a given color, 2 of these categories would be false, and the other would be true:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0paFk43GNvh3"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|True|False|False|\n",
        "|Green|False|False|True|\n",
        "|Blue|False|True|False|\n",
        "|Green|False|False|True|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udaf7UQTNvh4"
      },
      "source": [
        "Rather than use \"True\" or \"False\", we could represent the same using binary, either 0 or 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ateIq_CyNvh4"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|1|0|0|\n",
        "|Green|0|0|1|\n",
        "|Blue|0|1|0|\n",
        "|Green|0|0|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNwUs6RtNvh4"
      },
      "source": [
        "This is what categorical encoding is, transforming values which are intended to be understood as categorical labels into a representation that makes their categorical nature explicit to the model. Thus, if we were using these values for training, we would convert..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D0gySHCNvh4"
      },
      "source": [
        "```python\n",
        "values = ['red, green, blue, green']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbIm1SLLNvh4"
      },
      "source": [
        "... which a neural network would have a very difficult time making sense of, instead to:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_x4QEyENvh5"
      },
      "source": [
        "```python\n",
        "values = [\n",
        "    [1, 0, 0],\n",
        "    [0, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1]\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XckPYgwNNvh5"
      },
      "source": [
        "### Categorically Encoding the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLg8cW_eNvh5"
      },
      "source": [
        "Keras provides a utility to [categorically encode values](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical), and here we use it to perform categorical encoding for both the training and validation labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TM1q8p6tNvh5"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "num_categories = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kYKSUlMNvh5"
      },
      "source": [
        "Here are the first 10 values of the training labels, which you can see have now been categorically encoded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwKcU1e_Nvh6",
        "outputId": "f45c4aa9-4cfa-4dc3-8333-6c7abc4c9273"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_train[0:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YmJ9evPNvh6"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDRtzGMWNvh6"
      },
      "source": [
        "With the data prepared for training, it is now time to create the model that we will train with the data. This first basic model will be made up of several *layers* and will be comprised of 3 main parts:\n",
        "\n",
        "1. An input layer, which will receive data in some expected format\n",
        "2. Several [hidden layers](https://developers.google.com/machine-learning/glossary#hidden-layer), each comprised of many *neurons*. Each [neuron](https://developers.google.com/machine-learning/glossary#neuron) will have the ability to affect the network's guess with its *weights*, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
        "3. An output layer, which will depict the network's guess for a given image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mIn54S0Nvh6"
      },
      "source": [
        "### Instantiating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWCIveKKNvh6"
      },
      "source": [
        "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "glRtCcPZNvh7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR9xEONyNvh7"
      },
      "source": [
        "### Creating the Input Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0n-avDeNvh7"
      },
      "source": [
        "Next, we will add the input layer. This layer will be *densely connected*, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Keras's [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "olM1PAqXNvh7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FA7tP_QNvh7"
      },
      "source": [
        "The `units` argument specifies the number of neurons in the layer. We are going to use `512` which we have chosen from experimentation. Choosing the correct number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset. Try playing around with this value later to see how it affects training and to start developing a sense for what this number means.\n",
        "\n",
        "We will learn more about activation functions later, but for now, we will use the `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function.\n",
        "\n",
        "The `input_shape` value specifies the shape of the incoming data which in our situation is a 1D array of 784 values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrlyuPiKNvh8",
        "outputId": "4e1a4d91-015e-488e-d3a8-1375e392c392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNRgXaCFNvh8"
      },
      "source": [
        "### Creating the Hidden Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-PEICKhNvh8"
      },
      "source": [
        "Now we will add an additional densely connected layer. Again, much more will be said about these later, but for now know that these layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "o-HdbB45Nvh8"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 512, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r-_xCClNvh8"
      },
      "source": [
        "### Creating the Output Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qPq3q9NNvh8"
      },
      "source": [
        "Finally, we will add an output layer. This layer uses the activation function `softmax` which will result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 10 possible categories, there will be 10 outputs. Each output gives the model's guess (a probability) that the image belongs to that specific class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MEMmsXY-Nvh9"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJsN37y-Nvh9"
      },
      "source": [
        "### Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kojRKQAfNvh9"
      },
      "source": [
        "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "9P-nGb7eNvh9",
        "outputId": "4571a445-3bca-485e-ab32-6341831bb050"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m669,706\u001b[0m (2.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">669,706</span> (2.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m669,706\u001b[0m (2.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">669,706</span> (2.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r0AjeNQNvh9"
      },
      "source": [
        "Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtFzHzpONvh9"
      },
      "source": [
        "### Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31AKA4jgNvh-"
      },
      "source": [
        "Again, more details are to follow, but the final step we need to do before we can actually train our model with data is to [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) it. Here we specify a [loss function](https://developers.google.com/machine-learning/glossary#loss) which will be used for the model to understand how well it is performing during training. We also specify that we would like to track `accuracy` while the model trains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2Oc3l9oiNvh-"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruRpF6X3Nvh-"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU9AhCZ5Nvh-"
      },
      "source": [
        "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
        "\n",
        "\"Training a model with data\" is often also called \"fitting a model to data.\" Put this latter way, it highlights that the shape of the model changes over time to more accurately understand the data that it is being given.\n",
        "\n",
        "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
        "\n",
        "* The training data\n",
        "* The labels for the training data\n",
        "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
        "* The validation or test data, and its labels\n",
        "\n",
        "Run the cell below to train the model. We will discuss its output after the training completes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXHX4wzbNvh-",
        "outputId": "a787a4cb-2be8-4b23-f48c-bd2e34ad4518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.3099 - val_accuracy: 0.9591 - val_loss: 0.1291\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0837 - val_accuracy: 0.9734 - val_loss: 0.0935\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0571 - val_accuracy: 0.9810 - val_loss: 0.0734\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0426 - val_accuracy: 0.9789 - val_loss: 0.0913\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0340 - val_accuracy: 0.9785 - val_loss: 0.0990\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3QNzhYxmNvh-"
      },
      "outputs": [],
      "source": [
        "chart_x = range(1,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-PQAr2pNvh_",
        "outputId": "7a165581-6465-44fc-b9a4-fa8916381295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
          ]
        }
      ],
      "source": [
        "chart_y_train = history.history['loss']\n",
        "chart_y_test = history.history['val_loss']\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "oGc9SPTYNvh_",
        "outputId": "10b981c3-bcda-455d-d5fd-b9124f91c566"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning():\n",
        "    plt.plot(chart_x, chart_y_train, 'r-',label='training error')\n",
        "    plt.plot(chart_x, chart_y_test, 'b-',\n",
        "    label='test error')\n",
        "    #plt.axis([0, len(chart_x), 0.0, 1.0])\n",
        "    plt.xlabel('training epochs')\n",
        "    plt.ylabel('error')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_learning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOPieB8rNvh_"
      },
      "source": [
        "### Observing Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3e1h-K5Nvh_"
      },
      "source": [
        "For each of the 5 epochs, notice the `accuracy` and `val_accuracy` scores. `accuracy` states how well the model did for the epoch on all the training data. `val_accuracy` states how well the model did on the validation data, which if you recall, was not used at all for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlRQCWMFNvh_"
      },
      "source": [
        "The model did quite well! The accuracy quickly reached close to 100%, as did the validation accuracy. We now have a model that can be used to accurately detect and classify hand-written images.\n",
        "\n",
        "The next step would be to use this model to classify new not-yet-seen handwritten images. This is called [inference](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). We'll explore the process of inference in a later exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AflRAvj4Nvh_"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99QMGlSxNviA"
      },
      "source": [
        "MNIST is not only useful for its historical influence on Computer Vision, but it's also a great [benchmark](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf) and debugging tool."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import mnist\n"
      ],
      "metadata": {
        "id": "A2-lILr-Osff"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
        "x_train, x_valid = x_train / 255.0, x_valid / 255.0  # Normalize images\n"
      ],
      "metadata": {
        "id": "A43B4stGOwKe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten images\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_valid = x_valid.reshape(-1, 28*28)\n"
      ],
      "metadata": {
        "id": "zKWczhRwOzvj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to categorical encoding\n",
        "num_categories = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
      ],
      "metadata": {
        "id": "M53mRiSIO2nf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and train a model\n",
        "def build_and_train_model(activation_function, num_layers=2, epochs=5, early_stop=False):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(28*28,)))  # Input layer\n",
        "\n",
        "    # Add variable number of layers\n",
        "    for _ in range(num_layers):\n",
        "        model.add(layers.Dense(512, activation=activation_function))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    callbacks_list = []\n",
        "    if early_stop:\n",
        "        callbacks_list.append(callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True))\n",
        "\n",
        "    # Train the model and record training time\n",
        "    start_time = time.time()\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_valid, y_valid), verbose=1, callbacks=callbacks_list)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get final validation accuracy\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "    return training_time, val_accuracy, history"
      ],
      "metadata": {
        "id": "1FcA_ArCO7dU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different activation functions, layer depths, and epochs\n",
        "activations = ['relu', 'sigmoid', 'tanh', 'elu', 'swish', 'softplus']\n",
        "layers_list = [2, 3, 5]\n",
        "epochs_list = [5, 10]\n",
        "\n",
        "results = {}\n",
        "all_histories = {}\n",
        "for activation in activations:\n",
        "    results[activation] = {}\n",
        "    for num_layers in layers_list:\n",
        "        for epochs in epochs_list:\n",
        "            training_time, val_acc, history = build_and_train_model(activation, num_layers, epochs, early_stop=True)\n",
        "            results[activation][(num_layers, epochs)] = (training_time, val_acc)\n",
        "            all_histories[(activation, num_layers, epochs)] = history\n",
        "            print(f\"Activation: {activation}, Layers: {num_layers}, Epochs: {epochs}, Training Time: {training_time:.2f}s, Validation Accuracy: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcbX_W7PPFFE",
        "outputId": "9ded8f7a-09f9-4bac-9a36-c8753e9aa4ad"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.3111 - val_accuracy: 0.9697 - val_loss: 0.0946\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0819 - val_accuracy: 0.9706 - val_loss: 0.0951\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0542 - val_accuracy: 0.9742 - val_loss: 0.0827\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0411 - val_accuracy: 0.9760 - val_loss: 0.0885\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0312 - val_accuracy: 0.9767 - val_loss: 0.0914\n",
            "Activation: relu, Layers: 2, Epochs: 5, Training Time: 24.89s, Validation Accuracy: 0.9767\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3129 - val_accuracy: 0.9675 - val_loss: 0.1023\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0816 - val_accuracy: 0.9720 - val_loss: 0.0940\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0514 - val_accuracy: 0.9746 - val_loss: 0.0788\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0386 - val_accuracy: 0.9658 - val_loss: 0.1246\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0337 - val_accuracy: 0.9780 - val_loss: 0.0908\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0278 - val_accuracy: 0.9801 - val_loss: 0.0799\n",
            "Activation: relu, Layers: 2, Epochs: 10, Training Time: 28.83s, Validation Accuracy: 0.9801\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.3204 - val_accuracy: 0.9697 - val_loss: 0.0981\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0923 - val_accuracy: 0.9693 - val_loss: 0.1029\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0673 - val_accuracy: 0.9704 - val_loss: 0.1019\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0512 - val_accuracy: 0.9800 - val_loss: 0.0746\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0401 - val_accuracy: 0.9774 - val_loss: 0.0845\n",
            "Activation: relu, Layers: 3, Epochs: 5, Training Time: 26.77s, Validation Accuracy: 0.9774\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.3238 - val_accuracy: 0.9579 - val_loss: 0.1383\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0907 - val_accuracy: 0.9718 - val_loss: 0.0926\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0619 - val_accuracy: 0.9739 - val_loss: 0.0914\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0515 - val_accuracy: 0.9735 - val_loss: 0.0985\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0382 - val_accuracy: 0.9741 - val_loss: 0.1012\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0361 - val_accuracy: 0.9787 - val_loss: 0.0732\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0271 - val_accuracy: 0.9801 - val_loss: 0.0809\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0228 - val_accuracy: 0.9797 - val_loss: 0.0932\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0210 - val_accuracy: 0.9782 - val_loss: 0.0974\n",
            "Activation: relu, Layers: 3, Epochs: 10, Training Time: 43.91s, Validation Accuracy: 0.9782\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3823 - val_accuracy: 0.9528 - val_loss: 0.1737\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1181 - val_accuracy: 0.9637 - val_loss: 0.1273\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0838 - val_accuracy: 0.9688 - val_loss: 0.1146\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0706 - val_accuracy: 0.9777 - val_loss: 0.0922\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0552 - val_accuracy: 0.9734 - val_loss: 0.1073\n",
            "Activation: relu, Layers: 5, Epochs: 5, Training Time: 28.72s, Validation Accuracy: 0.9734\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.3751 - val_accuracy: 0.9650 - val_loss: 0.1324\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1205 - val_accuracy: 0.9680 - val_loss: 0.1250\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0827 - val_accuracy: 0.9751 - val_loss: 0.1009\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0693 - val_accuracy: 0.9772 - val_loss: 0.0921\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0526 - val_accuracy: 0.9761 - val_loss: 0.0943\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0432 - val_accuracy: 0.9784 - val_loss: 0.0954\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0407 - val_accuracy: 0.9754 - val_loss: 0.1092\n",
            "Activation: relu, Layers: 5, Epochs: 10, Training Time: 37.11s, Validation Accuracy: 0.9754\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.5910 - val_accuracy: 0.9414 - val_loss: 0.1879\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1521 - val_accuracy: 0.9632 - val_loss: 0.1177\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0907 - val_accuracy: 0.9709 - val_loss: 0.0942\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0620 - val_accuracy: 0.9746 - val_loss: 0.0803\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0451 - val_accuracy: 0.9784 - val_loss: 0.0707\n",
            "Activation: sigmoid, Layers: 2, Epochs: 5, Training Time: 29.96s, Validation Accuracy: 0.9784\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.6035 - val_accuracy: 0.9480 - val_loss: 0.1742\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1591 - val_accuracy: 0.9616 - val_loss: 0.1228\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0938 - val_accuracy: 0.9698 - val_loss: 0.0965\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0608 - val_accuracy: 0.9759 - val_loss: 0.0810\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0442 - val_accuracy: 0.9747 - val_loss: 0.0803\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0315 - val_accuracy: 0.9799 - val_loss: 0.0699\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0228 - val_accuracy: 0.9770 - val_loss: 0.0879\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0178 - val_accuracy: 0.9738 - val_loss: 0.1023\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0139 - val_accuracy: 0.9806 - val_loss: 0.0771\n",
            "Activation: sigmoid, Layers: 2, Epochs: 10, Training Time: 42.05s, Validation Accuracy: 0.9806\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.6781 - val_accuracy: 0.9509 - val_loss: 0.1685\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.1503 - val_accuracy: 0.9539 - val_loss: 0.1488\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0948 - val_accuracy: 0.9688 - val_loss: 0.1009\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0660 - val_accuracy: 0.9746 - val_loss: 0.0880\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0484 - val_accuracy: 0.9775 - val_loss: 0.0744\n",
            "Activation: sigmoid, Layers: 3, Epochs: 5, Training Time: 27.07s, Validation Accuracy: 0.9775\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.6944 - val_accuracy: 0.9424 - val_loss: 0.1840\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1550 - val_accuracy: 0.9590 - val_loss: 0.1324\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0984 - val_accuracy: 0.9694 - val_loss: 0.0962\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0689 - val_accuracy: 0.9717 - val_loss: 0.0903\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0489 - val_accuracy: 0.9751 - val_loss: 0.0854\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0402 - val_accuracy: 0.9746 - val_loss: 0.0875\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0279 - val_accuracy: 0.9801 - val_loss: 0.0732\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0223 - val_accuracy: 0.9777 - val_loss: 0.0933\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0179 - val_accuracy: 0.9735 - val_loss: 0.1084\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0168 - val_accuracy: 0.9805 - val_loss: 0.0817\n",
            "Activation: sigmoid, Layers: 3, Epochs: 10, Training Time: 48.21s, Validation Accuracy: 0.9805\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 0.9745 - val_accuracy: 0.9261 - val_loss: 0.2560\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1894 - val_accuracy: 0.9533 - val_loss: 0.1568\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1304 - val_accuracy: 0.9702 - val_loss: 0.1030\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0891 - val_accuracy: 0.9673 - val_loss: 0.1188\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0696 - val_accuracy: 0.9738 - val_loss: 0.1026\n",
            "Activation: sigmoid, Layers: 5, Epochs: 5, Training Time: 29.56s, Validation Accuracy: 0.9738\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.9689 - val_accuracy: 0.9302 - val_loss: 0.2487\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1886 - val_accuracy: 0.9579 - val_loss: 0.1478\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1247 - val_accuracy: 0.9629 - val_loss: 0.1258\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9735 - loss: 0.0915 - val_accuracy: 0.9732 - val_loss: 0.0949\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0694 - val_accuracy: 0.9730 - val_loss: 0.0961\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0529 - val_accuracy: 0.9763 - val_loss: 0.0917\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0424 - val_accuracy: 0.9780 - val_loss: 0.0846\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0371 - val_accuracy: 0.9754 - val_loss: 0.0836\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0298 - val_accuracy: 0.9739 - val_loss: 0.1029\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0261 - val_accuracy: 0.9788 - val_loss: 0.0846\n",
            "Activation: sigmoid, Layers: 5, Epochs: 10, Training Time: 51.92s, Validation Accuracy: 0.9788\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.3741 - val_accuracy: 0.9617 - val_loss: 0.1230\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.1137 - val_accuracy: 0.9649 - val_loss: 0.1145\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0752 - val_accuracy: 0.9708 - val_loss: 0.0953\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0534 - val_accuracy: 0.9709 - val_loss: 0.0998\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0460 - val_accuracy: 0.9753 - val_loss: 0.0799\n",
            "Activation: tanh, Layers: 2, Epochs: 5, Training Time: 29.21s, Validation Accuracy: 0.9753\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.3701 - val_accuracy: 0.9586 - val_loss: 0.1375\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1104 - val_accuracy: 0.9640 - val_loss: 0.1181\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0778 - val_accuracy: 0.9708 - val_loss: 0.0918\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0563 - val_accuracy: 0.9741 - val_loss: 0.0842\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0432 - val_accuracy: 0.9736 - val_loss: 0.0852\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0339 - val_accuracy: 0.9747 - val_loss: 0.0869\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0263 - val_accuracy: 0.9772 - val_loss: 0.0748\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.9757 - val_loss: 0.0932\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0230 - val_accuracy: 0.9760 - val_loss: 0.1060\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0205 - val_accuracy: 0.9775 - val_loss: 0.0852\n",
            "Activation: tanh, Layers: 2, Epochs: 10, Training Time: 45.98s, Validation Accuracy: 0.9775\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3958 - val_accuracy: 0.9514 - val_loss: 0.1563\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1342 - val_accuracy: 0.9646 - val_loss: 0.1165\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0943 - val_accuracy: 0.9706 - val_loss: 0.0953\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0688 - val_accuracy: 0.9653 - val_loss: 0.1254\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0621 - val_accuracy: 0.9746 - val_loss: 0.0882\n",
            "Activation: tanh, Layers: 3, Epochs: 5, Training Time: 25.90s, Validation Accuracy: 0.9746\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.3929 - val_accuracy: 0.9527 - val_loss: 0.1500\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1314 - val_accuracy: 0.9636 - val_loss: 0.1147\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0926 - val_accuracy: 0.9604 - val_loss: 0.1328\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0681 - val_accuracy: 0.9696 - val_loss: 0.1084\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0642 - val_accuracy: 0.9714 - val_loss: 0.0955\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0502 - val_accuracy: 0.9659 - val_loss: 0.1204\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0445 - val_accuracy: 0.9720 - val_loss: 0.0962\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0370 - val_accuracy: 0.9721 - val_loss: 0.0965\n",
            "Activation: tanh, Layers: 3, Epochs: 10, Training Time: 38.79s, Validation Accuracy: 0.9721\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.4669 - val_accuracy: 0.9199 - val_loss: 0.2690\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1864 - val_accuracy: 0.9524 - val_loss: 0.1646\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1405 - val_accuracy: 0.9620 - val_loss: 0.1290\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1106 - val_accuracy: 0.9604 - val_loss: 0.1378\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0960 - val_accuracy: 0.9659 - val_loss: 0.1252\n",
            "Activation: tanh, Layers: 5, Epochs: 5, Training Time: 27.80s, Validation Accuracy: 0.9659\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.4707 - val_accuracy: 0.9375 - val_loss: 0.2136\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1903 - val_accuracy: 0.9541 - val_loss: 0.1585\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1389 - val_accuracy: 0.9598 - val_loss: 0.1439\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1154 - val_accuracy: 0.9644 - val_loss: 0.1203\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0925 - val_accuracy: 0.9619 - val_loss: 0.1370\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0839 - val_accuracy: 0.9628 - val_loss: 0.1388\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0779 - val_accuracy: 0.9660 - val_loss: 0.1208\n",
            "Activation: tanh, Layers: 5, Epochs: 10, Training Time: 36.43s, Validation Accuracy: 0.9660\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.3656 - val_accuracy: 0.9616 - val_loss: 0.1244\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1234 - val_accuracy: 0.9657 - val_loss: 0.1158\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0859 - val_accuracy: 0.9651 - val_loss: 0.1168\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0660 - val_accuracy: 0.9756 - val_loss: 0.0911\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0577 - val_accuracy: 0.9749 - val_loss: 0.1008\n",
            "Activation: elu, Layers: 2, Epochs: 5, Training Time: 24.83s, Validation Accuracy: 0.9749\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.3740 - val_accuracy: 0.9539 - val_loss: 0.1496\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1262 - val_accuracy: 0.9608 - val_loss: 0.1365\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0860 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0689 - val_accuracy: 0.9776 - val_loss: 0.0840\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0554 - val_accuracy: 0.9680 - val_loss: 0.1308\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0463 - val_accuracy: 0.9716 - val_loss: 0.1319\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0444 - val_accuracy: 0.9762 - val_loss: 0.1115\n",
            "Activation: elu, Layers: 2, Epochs: 10, Training Time: 32.60s, Validation Accuracy: 0.9762\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.4007 - val_accuracy: 0.9439 - val_loss: 0.1741\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1515 - val_accuracy: 0.9577 - val_loss: 0.1491\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1089 - val_accuracy: 0.9707 - val_loss: 0.1000\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0851 - val_accuracy: 0.9738 - val_loss: 0.0947\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0792 - val_accuracy: 0.9629 - val_loss: 0.1338\n",
            "Activation: elu, Layers: 3, Epochs: 5, Training Time: 25.19s, Validation Accuracy: 0.9629\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.3925 - val_accuracy: 0.9593 - val_loss: 0.1398\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1543 - val_accuracy: 0.9646 - val_loss: 0.1259\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1111 - val_accuracy: 0.9704 - val_loss: 0.1112\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0893 - val_accuracy: 0.9738 - val_loss: 0.1154\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0793 - val_accuracy: 0.9706 - val_loss: 0.1263\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0717 - val_accuracy: 0.9732 - val_loss: 0.1133\n",
            "Activation: elu, Layers: 3, Epochs: 10, Training Time: 29.62s, Validation Accuracy: 0.9732\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.4909 - val_accuracy: 0.9452 - val_loss: 0.1871\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1904 - val_accuracy: 0.9590 - val_loss: 0.1578\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.1487 - val_accuracy: 0.9584 - val_loss: 0.1587\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1248 - val_accuracy: 0.9657 - val_loss: 0.1334\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.1076 - val_accuracy: 0.9695 - val_loss: 0.1201\n",
            "Activation: elu, Layers: 5, Epochs: 5, Training Time: 26.70s, Validation Accuracy: 0.9695\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.5016 - val_accuracy: 0.9425 - val_loss: 0.2011\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.2000 - val_accuracy: 0.9513 - val_loss: 0.1792\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1407 - val_accuracy: 0.9631 - val_loss: 0.1450\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1225 - val_accuracy: 0.9669 - val_loss: 0.1354\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.1113 - val_accuracy: 0.9726 - val_loss: 0.1050\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0806 - val_accuracy: 0.9753 - val_loss: 0.1036\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0701 - val_accuracy: 0.9710 - val_loss: 0.1140\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0774 - val_accuracy: 0.9805 - val_loss: 0.0924\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0633 - val_accuracy: 0.9750 - val_loss: 0.1433\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0656 - val_accuracy: 0.9776 - val_loss: 0.1114\n",
            "Activation: elu, Layers: 5, Epochs: 10, Training Time: 49.60s, Validation Accuracy: 0.9776\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.3371 - val_accuracy: 0.9682 - val_loss: 0.1010\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0879 - val_accuracy: 0.9733 - val_loss: 0.0905\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0544 - val_accuracy: 0.9752 - val_loss: 0.0837\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0367 - val_accuracy: 0.9758 - val_loss: 0.0872\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0285 - val_accuracy: 0.9733 - val_loss: 0.1061\n",
            "Activation: swish, Layers: 2, Epochs: 5, Training Time: 24.16s, Validation Accuracy: 0.9733\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.3357 - val_accuracy: 0.9642 - val_loss: 0.1095\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0850 - val_accuracy: 0.9745 - val_loss: 0.0820\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0524 - val_accuracy: 0.9702 - val_loss: 0.0962\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0390 - val_accuracy: 0.9788 - val_loss: 0.0735\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0279 - val_accuracy: 0.9812 - val_loss: 0.0670\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0251 - val_accuracy: 0.9765 - val_loss: 0.1033\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0217 - val_accuracy: 0.9798 - val_loss: 0.0862\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0182 - val_accuracy: 0.9803 - val_loss: 0.0951\n",
            "Activation: swish, Layers: 2, Epochs: 10, Training Time: 36.90s, Validation Accuracy: 0.9803\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.3525 - val_accuracy: 0.9606 - val_loss: 0.1249\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1038 - val_accuracy: 0.9704 - val_loss: 0.0954\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0689 - val_accuracy: 0.9768 - val_loss: 0.0827\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0488 - val_accuracy: 0.9739 - val_loss: 0.0958\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0394 - val_accuracy: 0.9758 - val_loss: 0.0909\n",
            "Activation: swish, Layers: 3, Epochs: 5, Training Time: 25.01s, Validation Accuracy: 0.9758\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.3519 - val_accuracy: 0.9514 - val_loss: 0.1517\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1059 - val_accuracy: 0.9698 - val_loss: 0.1013\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0697 - val_accuracy: 0.9719 - val_loss: 0.1038\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0543 - val_accuracy: 0.9792 - val_loss: 0.0746\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0402 - val_accuracy: 0.9777 - val_loss: 0.0917\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0344 - val_accuracy: 0.9775 - val_loss: 0.0835\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0306 - val_accuracy: 0.9821 - val_loss: 0.0832\n",
            "Activation: swish, Layers: 3, Epochs: 10, Training Time: 33.58s, Validation Accuracy: 0.9821\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.4099 - val_accuracy: 0.9619 - val_loss: 0.1455\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1257 - val_accuracy: 0.9632 - val_loss: 0.1523\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0893 - val_accuracy: 0.9679 - val_loss: 0.1282\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0682 - val_accuracy: 0.9761 - val_loss: 0.0977\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0502 - val_accuracy: 0.9757 - val_loss: 0.0939\n",
            "Activation: swish, Layers: 5, Epochs: 5, Training Time: 27.07s, Validation Accuracy: 0.9757\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.4119 - val_accuracy: 0.9602 - val_loss: 0.1367\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1363 - val_accuracy: 0.9700 - val_loss: 0.1000\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.0964 - val_accuracy: 0.9726 - val_loss: 0.1014\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0716 - val_accuracy: 0.9775 - val_loss: 0.0869\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0506 - val_accuracy: 0.9741 - val_loss: 0.1138\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0433 - val_accuracy: 0.9782 - val_loss: 0.0886\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0328 - val_accuracy: 0.9787 - val_loss: 0.0964\n",
            "Activation: swish, Layers: 5, Epochs: 10, Training Time: 36.58s, Validation Accuracy: 0.9787\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.4985 - val_accuracy: 0.9603 - val_loss: 0.1327\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1228 - val_accuracy: 0.9688 - val_loss: 0.0965\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0732 - val_accuracy: 0.9727 - val_loss: 0.0856\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0514 - val_accuracy: 0.9753 - val_loss: 0.0845\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0382 - val_accuracy: 0.9790 - val_loss: 0.0729\n",
            "Activation: softplus, Layers: 2, Epochs: 5, Training Time: 24.33s, Validation Accuracy: 0.9790\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.5087 - val_accuracy: 0.9521 - val_loss: 0.1496\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1248 - val_accuracy: 0.9671 - val_loss: 0.1072\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0799 - val_accuracy: 0.9710 - val_loss: 0.0891\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0520 - val_accuracy: 0.9705 - val_loss: 0.0992\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0387 - val_accuracy: 0.9746 - val_loss: 0.0871\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0268 - val_accuracy: 0.9782 - val_loss: 0.0821\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0220 - val_accuracy: 0.9805 - val_loss: 0.0771\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0156 - val_accuracy: 0.9807 - val_loss: 0.0856\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.9798 - val_loss: 0.0887\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0128 - val_accuracy: 0.9812 - val_loss: 0.0883\n",
            "Activation: softplus, Layers: 2, Epochs: 10, Training Time: 46.12s, Validation Accuracy: 0.9812\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.5668 - val_accuracy: 0.9493 - val_loss: 0.1659\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1293 - val_accuracy: 0.9686 - val_loss: 0.1029\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0813 - val_accuracy: 0.9726 - val_loss: 0.0858\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0570 - val_accuracy: 0.9785 - val_loss: 0.0716\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0447 - val_accuracy: 0.9783 - val_loss: 0.0783\n",
            "Activation: softplus, Layers: 3, Epochs: 5, Training Time: 25.10s, Validation Accuracy: 0.9783\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.5601 - val_accuracy: 0.9434 - val_loss: 0.1790\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1274 - val_accuracy: 0.9685 - val_loss: 0.1034\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0812 - val_accuracy: 0.9743 - val_loss: 0.0813\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0568 - val_accuracy: 0.9770 - val_loss: 0.0763\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0401 - val_accuracy: 0.9799 - val_loss: 0.0720\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0350 - val_accuracy: 0.9803 - val_loss: 0.0766\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0250 - val_accuracy: 0.9799 - val_loss: 0.0794\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0227 - val_accuracy: 0.9815 - val_loss: 0.0807\n",
            "Activation: softplus, Layers: 3, Epochs: 10, Training Time: 38.07s, Validation Accuracy: 0.9815\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.7645 - val_accuracy: 0.9463 - val_loss: 0.1734\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1448 - val_accuracy: 0.9668 - val_loss: 0.1131\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0964 - val_accuracy: 0.9734 - val_loss: 0.0952\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0657 - val_accuracy: 0.9665 - val_loss: 0.1254\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0550 - val_accuracy: 0.9792 - val_loss: 0.0785\n",
            "Activation: softplus, Layers: 5, Epochs: 5, Training Time: 26.77s, Validation Accuracy: 0.9792\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.6906 - val_accuracy: 0.9487 - val_loss: 0.1669\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9567 - loss: 0.1460 - val_accuracy: 0.9639 - val_loss: 0.1193\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.1021 - val_accuracy: 0.9710 - val_loss: 0.1001\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0713 - val_accuracy: 0.9744 - val_loss: 0.0953\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0566 - val_accuracy: 0.9784 - val_loss: 0.0858\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0430 - val_accuracy: 0.9791 - val_loss: 0.0745\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0372 - val_accuracy: 0.9794 - val_loss: 0.0851\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0302 - val_accuracy: 0.9814 - val_loss: 0.0737\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0228 - val_accuracy: 0.9808 - val_loss: 0.0953\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0239 - val_accuracy: 0.9803 - val_loss: 0.1202\n",
            "Activation: softplus, Layers: 5, Epochs: 10, Training Time: 49.69s, Validation Accuracy: 0.9803\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}